## 1. ç€šåšåŠå¯¼ä½“

![vastaitech](https://github.com/Vastai/VastModelZOO/blob/main/images/index/logo.png?raw=true)

- å®˜æ–¹ç½‘å€ï¼šhttps://www.vastaitech.com
- æ¨¡å‹ä¸­å¿ƒï¼šhttps://github.com/Vastai/VastModelZOO


## 2. æµ‹è¯•å¹³å°

- ä»¥ä¸‹ä¸ºæœ¬æŒ‡å—æµ‹è¯•ä½¿ç”¨çš„å¹³å°ä¿¡æ¯ï¼Œä¾›å‚è€ƒ
    ```
    os: Ubuntu-22.04.3-LTS-x86_64
    cpu: Hygon C86-4G
    gpu: VA16 / VA1L / VA10L
    torch: 2.8.0+cpu
    torch-vacc: 1.3.3.626
    vllm: 0.11.1.dev0+gb8b302cde.d20251030.cpu
    vllm-vacc: 0.11.0.626 
    driver: 00.25.12.02 d3_3_v2_9_a3_1 3ef7cf3 20251202
    docker: 28.1.1
    ```

## 3. ç¯å¢ƒå‡†å¤‡

- è·å–Dockeré•œåƒ
    ```bash
    sudo docker pull harbor.vastaitech.com/ai_deliver/vllm_vacc:VVI-25.12.SP1
    ```

- å¯åŠ¨Dockerå®¹å™¨
    ```bash
    sudo docker run -it \
        --privileged=true \
        --shm-size=256g \
        --name vllm_service \
        --ipc=host \
        --network=host \
        harbor.vastaitech.com/ai_deliver/vllm_vacc:VVI-25.12.SP1 bash
    ```


>[!TIP]
> - é•œåƒå†…å·²åŒ…å«`torch/vllm`ç­‰ç›¸å…³ä¾èµ–
> - å’Œ`NVIDIA`ç¡¬ä»¶ä¸‹`CUDA_VISIBLE_DEVICES`ç±»ä¼¼ï¼›åœ¨`VastAI`ç¡¬ä»¶ä¸­å¯ä»¥ä½¿ç”¨`VACC_VISIBLE_DEVICES`æŒ‡å®š`å¯è§è®¡ç®—å¡ID`ï¼Œå¦‚`-e VACC_VISIBLE_DEVICES=0,1,2,3`
> - éœ€æŒ‡å®šé€‚å½“çš„`--shm-size`è™šæ‹Ÿå†…å­˜

## 4. MinerUåŠŸèƒ½

>[!NOTE]
> - `VastAI`åŠ é€Ÿå¡ä»…æ”¯æŒä½¿ç”¨`vlm-vllm-engine`å’Œ`vlm-http-client`å½¢å¼è¿›è¡Œ`VLM`æ¨¡å‹æ¨ç†åŠ é€Ÿ

- è¿›å…¥å®¹å™¨
    ```bash
    sudo docker exec -it vllm_service bash
    ```

- å®‰è£…MinerU

   - å‚è€ƒå®˜æ–¹æ–‡æ¡£å®‰è£…ï¼š[README_zh-CN.md#å®‰è£…-mineru](https://github.com/opendatalab/MinerU/blob/master/README_zh-CN.md#å®‰è£…-mineru)

        ```bash
        # https://mirrors.163.com/pypi/simple/
        # https://mirrors.aliyun.com/pypi/simple/
        # https://pypi.mirrors.ustc.edu.cn/simple/
        # https://pypi.tuna.tsinghua.edu.cn/simple/
        # https://mirror.baidu.com/pypi/simple

        # é€šè¿‡æºç å®‰è£…MinerU
        git clone https://github.com/opendatalab/MinerU.git
        git checkout eed479eb56bba93ee99c1a8c255d509bd2f837e5
        pip install -e .[core] -i https://mirrors.aliyun.com/pypi/simple

        # ä½¿ç”¨pipå®‰è£…MinerU
        pip install -U "mineru[core]" -i https://mirrors.aliyun.com/pypi/simple
        ```

- ä½¿ç”¨MinerU

    - æ¨¡å‹å‡†å¤‡ï¼Œå‚è€ƒå®˜æ–¹ä»‹ç»ï¼š[model_source.md](https://github.com/opendatalab/MinerU/blob/master/docs/zh/usage/model_source.md)

    - æ–¹å¼ä¸€ï¼š`vlm-vllm-engine`

        ```bash
        export MINERU_MODEL_SOURCE=modelscope

        # step1, ä»¥`vlm-vllm-engine`æ–¹å¼å¯åŠ¨MinerUè§£æä»»åŠ¡
        mineru -p /path/to/demo/pdfs/demo1.pdf \
        -o ./output \
        -b vlm-vllm-engine \
        --http-timeout 1200 \
        --tensor-parallel-size 2 \
        --enforce_eager \
        --trust-remote-code \
        --max-model-len 16384
        ```

    - æ–¹å¼äºŒï¼š`vlm-http-client`

        ```bash
        # step1, å¯åŠ¨vLLM API server
        vllm serve /root/.cache/modelscope/hub/models/OpenDataLab/MinerU2.5-2509-1.2B \
        --tensor-parallel-size 2 \
        --trust-remote-code \
        --enforce_eager \
        --port 8090 \
        --max-model-len 16384 \
        --served-model-name MinerU2.5-2509-1.2B

        # step2ï¼Œä»¥`vlm-http-client`æ–¹å¼å¯åŠ¨MinerUè§£æä»»åŠ¡
        mineru -p /path/to/demo/pdfs/demo1.pdf \
        -o ./output \
        -b vlm-http-client \
        -u http://127.0.0.1:8090 \
        --http-timeout 1200
        ```


>[!NOTE]
> - æˆªè‡³`2025/12/23`ï¼Œ`VastAI`å·²æ”¯æŒ`MinerU`è‡³æœ€æ–°ç‰ˆæœ¬`2.6.8`ï¼Œ`masteråˆ†æ”¯eed479eb`
> - æ³¨æ„åœ¨æ‰§è¡Œä»»æ„ä¸`vllm`ç›¸å…³å‘½ä»¤éœ€è¿½åŠ `--enforce_eager`å‚æ•°


## 5. æ³¨æ„äº‹é¡¹

`VastAI`åŠ é€Ÿå¡å¯¹`MinerU`çš„æ”¯æŒæƒ…å†µå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š


<table border="1">
  <thead>
    <tr>
      <th rowspan="2" colspan="2">ä½¿ç”¨åœºæ™¯</th>
      <th>æ”¯æŒæƒ…å†µ</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="5">å‘½ä»¤è¡Œå·¥å…·(mineru)</td>
      <td>pipeline</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-transformers</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-vllm-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-lmdeploy-client</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td rowspan="5">fastapiæœåŠ¡(mineru-api)</td>
      <td>pipeline</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-transformers</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-vllm-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-lmdeploy-engine</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td rowspan="5">gradioç•Œé¢(mineru-gradio)</td>
      <td>pipeline</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-transformers</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-vllm-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-lmdeploy-engine</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>vlm-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td colspan="2">openai-serveræœåŠ¡ï¼ˆmineru-openai-serverï¼‰</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td colspan="2">Tensorå¹¶è¡Œ (--tensor-parallel-size/--tp)</td>
      <td>ğŸŸ¢ ä»…æ”¯æŒtp1/tp2</td>
    </tr>
    <tr>
      <td colspan="2">æ•°æ®å¹¶è¡Œ (--data-parallel-size/--dp)</td>
      <td>ğŸ”´</td>
    </tr>
  </tbody>
</table>


æ³¨ï¼š  
ğŸŸ¢: æ”¯æŒï¼Œè¿è¡Œè¾ƒç¨³å®šï¼Œç²¾åº¦ä¸Nvidia GPUåŸºæœ¬ä¸€è‡´  
ğŸŸ¡: æ”¯æŒä½†è¾ƒä¸ç¨³å®šï¼Œåœ¨æŸäº›åœºæ™¯ä¸‹å¯èƒ½å‡ºç°å¼‚å¸¸ï¼Œæˆ–ç²¾åº¦å­˜åœ¨ä¸€å®šå·®å¼‚  
ğŸ”´: ä¸æ”¯æŒï¼Œæ— æ³•è¿è¡Œï¼Œæˆ–ç²¾åº¦å­˜åœ¨è¾ƒå¤§å·®å¼‚
