"""
MinerU Tianshu - Task Scheduler (Optional)
å¤©æ¢ä»»åŠ¡è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰

åœ¨ Worker è‡ªåŠ¨å¾ªç¯æ¨¡å¼ä¸‹ï¼Œè°ƒåº¦å™¨ä¸»è¦ç”¨äºï¼š
1. ç›‘æ§é˜Ÿåˆ—çŠ¶æ€ï¼ˆé»˜è®¤5åˆ†é’Ÿä¸€æ¬¡ï¼‰
2. å¥åº·æ£€æŸ¥ï¼ˆé»˜è®¤15åˆ†é’Ÿä¸€æ¬¡ï¼‰
3. ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
4. æ•…éšœæ¢å¤ï¼ˆé‡ç½®è¶…æ—¶ä»»åŠ¡ï¼‰

æ³¨æ„ï¼š
- å¦‚æœ workers å¯ç”¨äº†è‡ªåŠ¨å¾ªç¯æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼Œåˆ™ä¸éœ€è¦è°ƒåº¦å™¨æ¥è§¦å‘ä»»åŠ¡å¤„ç†
- Worker å·²ç»ä¸»åŠ¨å·¥ä½œï¼Œè°ƒåº¦å™¨åªæ˜¯å¶å°”æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
- è¾ƒé•¿çš„é—´éš”å¯ä»¥æœ€å°åŒ–ç³»ç»Ÿå¼€é”€ï¼ŒåŒæ—¶ä¿æŒå¿…è¦çš„ç›‘æ§èƒ½åŠ›
- 5åˆ†é’Ÿç›‘æ§ã€15åˆ†é’Ÿå¥åº·æ£€æŸ¥å¯¹äºè‡ªåŠ¨è¿è¡Œçš„ç³»ç»Ÿæ¥è¯´å·²ç»è¶³å¤ŸåŠæ—¶
"""
import asyncio
import aiohttp
from loguru import logger
from task_db import TaskDB
import signal


class TaskScheduler:
    """
    ä»»åŠ¡è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰
    
    èŒè´£ï¼ˆåœ¨ Worker è‡ªåŠ¨å¾ªç¯æ¨¡å¼ä¸‹ï¼‰ï¼š
    1. ç›‘æ§ SQLite ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
    2. å¥åº·æ£€æŸ¥ Workers
    3. æ•…éšœæ¢å¤ï¼ˆé‡ç½®è¶…æ—¶ä»»åŠ¡ï¼‰
    4. æ”¶é›†å’Œå±•ç¤ºç»Ÿè®¡ä¿¡æ¯
    
    èŒè´£ï¼ˆåœ¨ä¼ ç»Ÿæ¨¡å¼ä¸‹ï¼‰ï¼š
    1. è§¦å‘ Workers æ‹‰å–ä»»åŠ¡
    """
    
    def __init__(
        self, 
        litserve_url='http://localhost:9000/predict', 
        monitor_interval=300,
        health_check_interval=900,
        stale_task_timeout=60,
        cleanup_old_files_days=7,
        cleanup_old_records_days=0,
        worker_auto_mode=True
    ):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨
        
        Args:
            litserve_url: LitServe Worker çš„ URL
            monitor_interval: ç›‘æ§é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤300ç§’=5åˆ†é’Ÿï¼‰
            health_check_interval: å¥åº·æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤900ç§’=15åˆ†é’Ÿï¼‰
            stale_task_timeout: è¶…æ—¶ä»»åŠ¡é‡ç½®æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            cleanup_old_files_days: æ¸…ç†å¤šå°‘å¤©å‰çš„ç»“æœæ–‡ä»¶ï¼ˆ0=ç¦ç”¨ï¼Œé»˜è®¤7å¤©ï¼‰
            cleanup_old_records_days: æ¸…ç†å¤šå°‘å¤©å‰çš„æ•°æ®åº“è®°å½•ï¼ˆ0=ç¦ç”¨ï¼Œä¸æ¨èåˆ é™¤ï¼‰
            worker_auto_mode: Worker æ˜¯å¦å¯ç”¨è‡ªåŠ¨å¾ªç¯æ¨¡å¼
        """
        self.litserve_url = litserve_url
        self.monitor_interval = monitor_interval
        self.health_check_interval = health_check_interval
        self.stale_task_timeout = stale_task_timeout
        self.cleanup_old_files_days = cleanup_old_files_days
        self.cleanup_old_records_days = cleanup_old_records_days
        self.worker_auto_mode = worker_auto_mode
        self.db = TaskDB()
        self.running = True
    
    async def check_worker_health(self, session: aiohttp.ClientSession):
        """
        æ£€æŸ¥ worker å¥åº·çŠ¶æ€
        """
        try:
            async with session.post(
                self.litserve_url,
                json={'action': 'health'},
                timeout=aiohttp.ClientTimeout(total=10)
            ) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    return result
                else:
                    logger.error(f"Health check failed with status {resp.status}")
                    return None
                    
        except asyncio.TimeoutError:
            logger.warning("Health check timeout")
            return None
        except Exception as e:
            logger.error(f"Health check error: {e}")
            return None
    
    async def schedule_loop(self):
        """
        ä¸»ç›‘æ§å¾ªç¯
        """
        logger.info("ğŸ”„ Task scheduler started")
        logger.info(f"   LitServe URL: {self.litserve_url}")
        logger.info(f"   Worker Mode: {'Auto-Loop' if self.worker_auto_mode else 'Scheduler-Driven'}")
        logger.info(f"   Monitor Interval: {self.monitor_interval}s")
        logger.info(f"   Health Check Interval: {self.health_check_interval}s")
        logger.info(f"   Stale Task Timeout: {self.stale_task_timeout}m")
        if self.cleanup_old_files_days > 0:
            logger.info(f"   Cleanup Old Files: {self.cleanup_old_files_days} days")
        else:
            logger.info(f"   Cleanup Old Files: Disabled")
        if self.cleanup_old_records_days > 0:
            logger.info(f"   Cleanup Old Records: {self.cleanup_old_records_days} days (Not Recommended)")
        else:
            logger.info(f"   Cleanup Old Records: Disabled (Keep Forever)")
        
        health_check_counter = 0
        stale_task_counter = 0
        cleanup_counter = 0
        
        async with aiohttp.ClientSession() as session:
            while self.running:
                try:
                    # 1. ç›‘æ§é˜Ÿåˆ—çŠ¶æ€
                    stats = self.db.get_queue_stats()
                    pending_count = stats.get('pending', 0)
                    processing_count = stats.get('processing', 0)
                    completed_count = stats.get('completed', 0)
                    failed_count = stats.get('failed', 0)
                    
                    if pending_count > 0 or processing_count > 0:
                        logger.info(
                            f"ğŸ“Š Queue: {pending_count} pending, {processing_count} processing, "
                            f"{completed_count} completed, {failed_count} failed"
                        )
                    
                    # 2. å®šæœŸå¥åº·æ£€æŸ¥
                    health_check_counter += 1
                    if health_check_counter * self.monitor_interval >= self.health_check_interval:
                        health_check_counter = 0
                        logger.info("ğŸ¥ Performing health check...")
                        health_result = await self.check_worker_health(session)
                        if health_result:
                            logger.info(f"âœ… Workers healthy: {health_result}")
                        else:
                            logger.warning("âš ï¸  Workers health check failed")
                    
                    # 3. å®šæœŸé‡ç½®è¶…æ—¶ä»»åŠ¡
                    stale_task_counter += 1
                    if stale_task_counter * self.monitor_interval >= self.stale_task_timeout * 60:
                        stale_task_counter = 0
                        reset_count = self.db.reset_stale_tasks(self.stale_task_timeout)
                        if reset_count > 0:
                            logger.warning(f"âš ï¸  Reset {reset_count} stale tasks (timeout: {self.stale_task_timeout}m)")
                    
                    # 4. å®šæœŸæ¸…ç†æ—§ä»»åŠ¡æ–‡ä»¶å’Œè®°å½•
                    cleanup_counter += 1
                    # æ¯24å°æ—¶æ¸…ç†ä¸€æ¬¡ï¼ˆåŸºäºå½“å‰ç›‘æ§é—´éš”è®¡ç®—ï¼‰
                    cleanup_interval_cycles = (24 * 3600) / self.monitor_interval
                    if cleanup_counter >= cleanup_interval_cycles:
                        cleanup_counter = 0
                        
                        # æ¸…ç†æ—§ç»“æœæ–‡ä»¶ï¼ˆä¿ç•™æ•°æ®åº“è®°å½•ï¼‰
                        if self.cleanup_old_files_days > 0:
                            logger.info(f"ğŸ§¹ Cleaning up result files older than {self.cleanup_old_files_days} days...")
                            file_count = self.db.cleanup_old_task_files(days=self.cleanup_old_files_days)
                            if file_count > 0:
                                logger.info(f"âœ… Cleaned up {file_count} result directories (DB records kept)")
                        
                        # æ¸…ç†ææ—§çš„æ•°æ®åº“è®°å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸å¯ç”¨ï¼‰
                        if self.cleanup_old_records_days > 0:
                            logger.warning(
                                f"ğŸ—‘ï¸  Cleaning up database records older than {self.cleanup_old_records_days} days..."
                            )
                            record_count = self.db.cleanup_old_task_records(days=self.cleanup_old_records_days)
                            if record_count > 0:
                                logger.warning(f"âš ï¸  Deleted {record_count} task records permanently")
                    
                    # ç­‰å¾…ä¸‹ä¸€æ¬¡ç›‘æ§
                    await asyncio.sleep(self.monitor_interval)
                    
                except Exception as e:
                    logger.error(f"Scheduler loop error: {e}")
                    await asyncio.sleep(self.monitor_interval)
        
        logger.info("â¹ï¸  Task scheduler stopped")
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        logger.info("ğŸš€ Starting MinerU Tianshu Task Scheduler...")
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        def signal_handler(sig, frame):
            logger.info("\nğŸ›‘ Received stop signal, shutting down...")
            self.running = False
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # è¿è¡Œè°ƒåº¦å¾ªç¯
        asyncio.run(self.schedule_loop())
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.running = False


async def health_check(litserve_url: str) -> bool:
    """
    å¥åº·æ£€æŸ¥ï¼šéªŒè¯ LitServe Worker æ˜¯å¦å¯ç”¨
    """
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(
                litserve_url.replace('/predict', '/health'),
                timeout=aiohttp.ClientTimeout(total=5)
            ) as resp:
                return resp.status == 200
    except:
        return False


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='MinerU Tianshu Task Scheduler (Optional)')
    parser.add_argument('--litserve-url', type=str, default='http://localhost:9000/predict',
                       help='LitServe worker URL')
    parser.add_argument('--monitor-interval', type=int, default=300,
                       help='Monitor interval in seconds (default: 300s = 5 minutes)')
    parser.add_argument('--health-check-interval', type=int, default=900,
                       help='Health check interval in seconds (default: 900s = 15 minutes)')
    parser.add_argument('--stale-task-timeout', type=int, default=60,
                       help='Timeout for stale tasks in minutes (default: 60)')
    parser.add_argument('--cleanup-old-files-days', type=int, default=7,
                       help='Delete result files older than N days (0=disable, default: 7)')
    parser.add_argument('--cleanup-old-records-days', type=int, default=0,
                       help='Delete DB records older than N days (0=disable, NOT recommended)')
    parser.add_argument('--wait-for-workers', action='store_true',
                       help='Wait for workers to be ready before starting')
    parser.add_argument('--no-worker-auto-mode', action='store_true',
                       help='Disable worker auto-loop mode assumption')
    
    args = parser.parse_args()
    
    # ç­‰å¾… workers å°±ç»ªï¼ˆå¯é€‰ï¼‰
    if args.wait_for_workers:
        logger.info("â³ Waiting for LitServe workers to be ready...")
        import time
        max_retries = 30
        for i in range(max_retries):
            if asyncio.run(health_check(args.litserve_url)):
                logger.info("âœ… LitServe workers are ready!")
                break
            time.sleep(2)
            if i == max_retries - 1:
                logger.error("âŒ LitServe workers not responding, starting anyway...")
    
    # åˆ›å»ºå¹¶å¯åŠ¨è°ƒåº¦å™¨
    scheduler = TaskScheduler(
        litserve_url=args.litserve_url,
        monitor_interval=args.monitor_interval,
        health_check_interval=args.health_check_interval,
        stale_task_timeout=args.stale_task_timeout,
        cleanup_old_files_days=args.cleanup_old_files_days,
        cleanup_old_records_days=args.cleanup_old_records_days,
        worker_auto_mode=not args.no_worker_auto_mode
    )
    
    try:
        scheduler.start()
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ Scheduler interrupted by user")

